{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/data/gaze_estimation/at_step_0060000.pth.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/root/data/gaze_estimation/at_step_0060000.pth.tar\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m ckpt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(ckpt_path, map_location\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m ckpt\u001b[39m.\u001b[39mkeys()\n",
      "File \u001b[0;32m/home/user/micromamba/lib/python3.10/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m/home/user/micromamba/lib/python3.10/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/home/user/micromamba/lib/python3.10/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/data/gaze_estimation/at_step_0060000.pth.tar'"
     ]
    }
   ],
   "source": [
    "ckpt_path = '/root/data/gaze_estimation/at_step_0060000.pth.tar'\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG_Gaze_Estimator(\n",
       "  (vgg16): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (FC1): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (FC2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (FC3): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (leakly_relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import VGG model\n",
    "from torchvision import models\n",
    "\n",
    "class VGG_Gaze_Estimator(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(VGG_Gaze_Estimator, self).__init__()\n",
    "        self.vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        # discard FC layers\n",
    "        self.vgg16 = self.vgg16.features\n",
    "\n",
    "        self.FC1 = nn.Linear(512, 64, bias=True)\n",
    "        self.FC2 = nn.Linear(64, 64, bias=True)\n",
    "        self.FC3 = nn.Linear(64, 4, bias=True)\n",
    "\n",
    "        self.leakly_relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # initialize weights\n",
    "        nn.init.kaiming_normal_(self.FC1.weight.data)\n",
    "        nn.init.constant_(self.FC1.bias.data, val=0)\n",
    "        nn.init.kaiming_normal_(self.FC2.weight.data)\n",
    "        nn.init.constant_(self.FC2.bias.data, val=0)\n",
    "        nn.init.kaiming_normal_(self.FC3.weight.data)\n",
    "        nn.init.constant_(self.FC3.bias.data, val=0)\n",
    "\n",
    "    def forward(self, x, feature_out_layers: list = None):\n",
    "        features = []\n",
    "        for i, layer in enumerate(self.vgg16):\n",
    "            x = layer(x)\n",
    "            if i in feature_out_layers:\n",
    "                features.append(x)\n",
    "        #print(x.shape)\n",
    "        x = x.mean(-1).mean(-1) # global average pooling\n",
    "        #print(x.shape, \"after global average pooling\")\n",
    "        x = self.leakly_relu(self.FC1(x))\n",
    "        x = self.leakly_relu(self.FC2(x))\n",
    "        x = self.tanh(self.FC3(x))\n",
    "        x = torch.pi * x * 0.5\n",
    "        gaze_estimate = x[:, :2]\n",
    "        head_estimate = x[:, 2:]\n",
    "        return gaze_estimate, head_estimate, features \\\n",
    "            if feature_out_layers is not None \\\n",
    "            else None\n",
    "\n",
    "# ---\n",
    "\n",
    "test_model = VGG_Gaze_Estimator()\n",
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "layer 3: torch.Size([1, 64, 128, 128])\n",
      "layer 8: torch.Size([1, 128, 64, 64])\n",
      "layer 15: torch.Size([1, 256, 32, 32])\n",
      "layer 22: torch.Size([1, 512, 16, 16])\n",
      "layer 29: torch.Size([1, 512, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "#test_model.load_state_dict(ckpt)\n",
    "test_X = torch.randn(1, 3, 128, 128)\n",
    "test_out = test_model(test_X, feature_out_layers=[3, 8, 15, 22, 29])\n",
    "print(len(test_out))\n",
    "for i, layer in enumerate(test_out[-1]):\n",
    "    print(f\"layer {[3, 8, 15, 22, 29][i]}: {layer.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0: torch.Size([1, 64, 128, 128])\n",
      "layer 1: torch.Size([1, 64, 128, 128])\n",
      "layer 2: torch.Size([1, 64, 128, 128])\n",
      "layer 3: torch.Size([1, 64, 128, 128])\n",
      "layer 4: torch.Size([1, 64, 64, 64])\n",
      "layer 5: torch.Size([1, 128, 64, 64])\n",
      "layer 6: torch.Size([1, 128, 64, 64])\n",
      "layer 7: torch.Size([1, 128, 64, 64])\n",
      "layer 8: torch.Size([1, 128, 64, 64])\n",
      "layer 9: torch.Size([1, 128, 32, 32])\n",
      "layer 10: torch.Size([1, 256, 32, 32])\n",
      "layer 11: torch.Size([1, 256, 32, 32])\n",
      "layer 12: torch.Size([1, 256, 32, 32])\n",
      "layer 13: torch.Size([1, 256, 32, 32])\n",
      "layer 14: torch.Size([1, 256, 32, 32])\n",
      "layer 15: torch.Size([1, 256, 32, 32])\n",
      "layer 16: torch.Size([1, 256, 16, 16])\n",
      "layer 17: torch.Size([1, 512, 16, 16])\n",
      "layer 18: torch.Size([1, 512, 16, 16])\n",
      "layer 19: torch.Size([1, 512, 16, 16])\n",
      "layer 20: torch.Size([1, 512, 16, 16])\n",
      "layer 21: torch.Size([1, 512, 16, 16])\n",
      "layer 22: torch.Size([1, 512, 16, 16])\n",
      "layer 23: torch.Size([1, 512, 8, 8])\n",
      "layer 24: torch.Size([1, 512, 8, 8])\n",
      "layer 25: torch.Size([1, 512, 8, 8])\n",
      "layer 26: torch.Size([1, 512, 8, 8])\n",
      "layer 27: torch.Size([1, 512, 8, 8])\n",
      "layer 28: torch.Size([1, 512, 8, 8])\n",
      "layer 29: torch.Size([1, 512, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "test_out = test_model(test_X, feature_out_layers=[i for i in range(30)])\n",
    "for i, layer in enumerate(test_out[-1]):\n",
    "    print(f\"layer {i}: {layer.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m/root/data/dataset_prep\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mSTEDGaze\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdataset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m gazeCaptureDataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mHDFDataset(\n\u001b[1;32m      7\u001b[0m     hdf_file_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/root/data/dataset_prep/faze_preprocess/outputs_sted/GazeCapture.h5\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/data/dataset_prep/STEDGaze/dataset.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m DefaultConfig\n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'core'"
     ]
    }
   ],
   "source": [
    "# add os path\n",
    "import sys\n",
    "sys.path.append('/root/data/dataset_prep')\n",
    "import STEDGaze.dataset as dataset\n",
    "\n",
    "gazeCaptureDataset = dataset.HDFDataset(\n",
    "    hdf_file_path='/root/data/dataset_prep/faze_preprocess/outputs_sted/GazeCapture.h5'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
